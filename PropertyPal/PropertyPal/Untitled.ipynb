{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcb6311d-bea0-4025-bfc7-2812e425048f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6331e1f0cdb74160b5cb3b7e94c34ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Turabi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\Turabi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\Turabi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "C:\\Users\\Turabi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "import torch\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import Document\n",
    "\n",
    "class CustomOutputParser:\n",
    "    def parse(self, response: str):\n",
    "        # Custom parsing logic to get the relevant response\n",
    "        # Assuming the response has a specific format\n",
    "        # Adjust the parsing logic based on your LLM's response format\n",
    "        parts = response.split('[/INST]')\n",
    "        if len(parts) > 1:\n",
    "            return parts[-1].strip()\n",
    "        return response.strip()\n",
    "\n",
    "class LLMRAGModel:\n",
    "    def __init__(self, llm_name=\"NousResearch/Llama-2-7b-chat-hf\"):\n",
    "        self.load_model(llm_name)\n",
    "        self.setup_pipeline()\n",
    "        self.retriever = self.buildRetrieval()  # Build the retriever once during initialization\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        # Load LLM with quantization configuration\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.float16\n",
    "        )\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            quantization_config=bnb_config\n",
    "        )\n",
    "\n",
    "    def setup_pipeline(self):\n",
    "        # Set up the text generation pipeline\n",
    "        self.llmPipeline = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            max_new_tokens=400,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        self.llm = HuggingFacePipeline(\n",
    "            pipeline=self.llmPipeline, \n",
    "            model_kwargs={'temperature': 0.1, 'max_length': 350, 'top_k': 10}\n",
    "        )\n",
    "\n",
    "    def generate_text(self, prompt):\n",
    "        # Generate text using the pipeline\n",
    "        return self.llmPipeline(prompt)\n",
    "\n",
    "    def getPromptFromTemplate(self):\n",
    "        system_prompt = \"\"\"You are PropertyPal, a specialized assistant designed to provide property recommendations based exclusively on the data given to you. Your responses should be based solely on the user's specific queries regarding property details and should reflect only the data available in the dataset.\n",
    "\n",
    "1. If the user asks for property recommendations, provide the following details for each property that matches their criteria:\n",
    "   - Location\n",
    "   - Number of bedrooms\n",
    "   - Number of bathrooms\n",
    "   - Property size\n",
    "   - Price\n",
    "\n",
    "2. Do not include any additional details such as property IDs, extra information, or suggestions beyond what is present in the dataset.\n",
    "\n",
    "3. If the user's input is a generic greeting or does not pertain to property recommendations, respond with a neutral message indicating that you can help with property queries and ask them to specify their requirements.\n",
    "\n",
    "Your responses should be concise and focused on the data provided, with no additional or extraneous details.\"\"\"\n",
    "\n",
    "        B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "        B_SYS, E_SYS = \" << SYS>>\\n\", \"\\n << /SYS>>\\n\\n\"\n",
    "\n",
    "        SYSTEM_PROMPT1 = B_SYS + system_prompt + E_SYS\n",
    "\n",
    "        instruction = \"\"\"\n",
    "        History: {history} \\n\n",
    "        Context: {context} \\n\n",
    "        User: {question}\"\"\"\n",
    "\n",
    "        prompt_template = B_INST + SYSTEM_PROMPT1 + instruction + E_INST\n",
    "\n",
    "        prompt = PromptTemplate(input_variables=[\"history\", \"question\", \"context\"], template=prompt_template)\n",
    "\n",
    "        return prompt\n",
    "\n",
    "    def buildRetrieval(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\", csv_file=None):\n",
    "        if csv_file is None:\n",
    "            csv_file = r\"C:\\Users\\Turabi\\OneDrive\\Desktop\\PropertyPal\\PropertyPal\\properties.csv\"\n",
    "\n",
    "        # Load the CSV file into a DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Create documents from the DataFrame\n",
    "        documents = df.apply(lambda row: Document(\n",
    "            page_content=f\"Property is located in {row['location']}. The price of the property is {row['price']}. It has {row['bedrooms']} bedrooms and {row['bathrooms']} bathrooms. The size of the property is {row['size']} square feet.\",\n",
    "            metadata=row.to_dict()\n",
    "        ), axis=1).tolist()\n",
    "\n",
    "        # Extract texts for embedding\n",
    "        texts = [doc.page_content for doc in documents]\n",
    "\n",
    "        # Initialize embeddings and vector store\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=250, chunk_overlap=100, separator=\"feet.\")\n",
    "        texts = text_splitter.split_documents([Document(page_content=text) for text in texts])\n",
    "\n",
    "        db = FAISS.from_documents(texts, embeddings)\n",
    "        retriever = db.as_retriever()\n",
    "\n",
    "        return retriever\n",
    "\n",
    "    def getNewChain(self):\n",
    "        prompt = self.getPromptFromTemplate()\n",
    "        memory = ConversationBufferMemory(input_key=\"question\", memory_key=\"history\", max_len=5)\n",
    "        llm_chain = LLMChain(prompt=prompt, llm=self.llm, verbose=True, memory=memory)\n",
    "        rag_chain = (\n",
    "            {\"context\": self.retriever, \"question\": lambda x: x}\n",
    "            | llm_chain\n",
    "        )\n",
    "        return rag_chain\n",
    "\n",
    "model_instance = LLMRAGModel()\n",
    "\n",
    "# Function to get answers from the chain\n",
    "def getAnswer(chain, question):\n",
    "    # Invoke the chain and get the response\n",
    "    response = chain.invoke(question)\n",
    "    # Assuming the response is a dictionary and `text` key contains the response text\n",
    "    response_text = response.get('text', 'No response text found')\n",
    "    # Use the custom output parser to clean up the response\n",
    "    parser = CustomOutputParser()\n",
    "    return parser.parse(response_text)\n",
    "\n",
    "\n",
    "# Create a new chain using the model instance\n",
    "chain = model_instance.getNewChain()\n",
    "\n",
    "# Example usage\n",
    "# answer = getAnswer(chain, \"I'm looking for a property in Navy Housing Scheme Karsaz, Karachi which should have 5 bedrooms and price should be 102500000\")\n",
    "# print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65502e06-a433-4701-a977-fc78148ec0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Debug for dnntrb@gmail.com\" as SERVER\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m[INST] << SYS>>\n",
      "You are PropertyPal, a specialized assistant designed to provide property recommendations based exclusively on the data given to you. Your responses should be based solely on the user's specific queries regarding property details and should reflect only the data available in the dataset.\n",
      "\n",
      "1. If the user asks for property recommendations, provide the following details for each property that matches their criteria:\n",
      "   - Location\n",
      "   - Number of bedrooms\n",
      "   - Number of bathrooms\n",
      "   - Property size\n",
      "   - Price\n",
      "\n",
      "2. Do not include any additional details such as property IDs, extra information, or suggestions beyond what is present in the dataset.\n",
      "\n",
      "3. If the user's input is a generic greeting or does not pertain to property recommendations, respond with a neutral message indicating that you can help with property queries and ask them to specify their requirements.\n",
      "\n",
      "Your responses should be concise and focused on the data provided, with no additional or extraneous details.\n",
      " << /SYS>>\n",
      "\n",
      "\n",
      "        History:  \n",
      "\n",
      "        Context: [Document(page_content='Property is located in ARY Laguna, DHA City Karachi, Karachi. The price of the property is 7600000. It has 0 bedrooms and 0 bathrooms. The size of the property is 846.0 square'), Document(page_content='Property is located in ARY Laguna, DHA City Karachi, Karachi. The price of the property is 9550000. It has 2 bedrooms and 2 bathrooms. The size of the property is 1026.0 square'), Document(page_content='Property is located in ARY Laguna, DHA City Karachi, Karachi. The price of the property is 7600000. It has 2 bedrooms and 2 bathrooms. The size of the property is 846.0 square'), Document(page_content='Property is located in Goldcrest Highlife, DHA Defence Phase 2, Islamabad. The price of the property is 12300000. It has 2 bedrooms and 2 bathrooms. The size of the property is 1305.0 square')] \n",
      "\n",
      "        User: hi[/INST]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m[INST] << SYS>>\n",
      "You are PropertyPal, a specialized assistant designed to provide property recommendations based exclusively on the data given to you. Your responses should be based solely on the user's specific queries regarding property details and should reflect only the data available in the dataset.\n",
      "\n",
      "1. If the user asks for property recommendations, provide the following details for each property that matches their criteria:\n",
      "   - Location\n",
      "   - Number of bedrooms\n",
      "   - Number of bathrooms\n",
      "   - Property size\n",
      "   - Price\n",
      "\n",
      "2. Do not include any additional details such as property IDs, extra information, or suggestions beyond what is present in the dataset.\n",
      "\n",
      "3. If the user's input is a generic greeting or does not pertain to property recommendations, respond with a neutral message indicating that you can help with property queries and ask them to specify their requirements.\n",
      "\n",
      "Your responses should be concise and focused on the data provided, with no additional or extraneous details.\n",
      " << /SYS>>\n",
      "\n",
      "\n",
      "        History: Human: hi\n",
      "AI: [INST] << SYS>>\n",
      "You are PropertyPal, a specialized assistant designed to provide property recommendations based exclusively on the data given to you. Your responses should be based solely on the user's specific queries regarding property details and should reflect only the data available in the dataset.\n",
      "\n",
      "1. If the user asks for property recommendations, provide the following details for each property that matches their criteria:\n",
      "   - Location\n",
      "   - Number of bedrooms\n",
      "   - Number of bathrooms\n",
      "   - Property size\n",
      "   - Price\n",
      "\n",
      "2. Do not include any additional details such as property IDs, extra information, or suggestions beyond what is present in the dataset.\n",
      "\n",
      "3. If the user's input is a generic greeting or does not pertain to property recommendations, respond with a neutral message indicating that you can help with property queries and ask them to specify their requirements.\n",
      "\n",
      "Your responses should be concise and focused on the data provided, with no additional or extraneous details.\n",
      " << /SYS>>\n",
      "\n",
      "\n",
      "        History:  \n",
      "\n",
      "        Context: [Document(page_content='Property is located in ARY Laguna, DHA City Karachi, Karachi. The price of the property is 7600000. It has 0 bedrooms and 0 bathrooms. The size of the property is 846.0 square'), Document(page_content='Property is located in ARY Laguna, DHA City Karachi, Karachi. The price of the property is 9550000. It has 2 bedrooms and 2 bathrooms. The size of the property is 1026.0 square'), Document(page_content='Property is located in ARY Laguna, DHA City Karachi, Karachi. The price of the property is 7600000. It has 2 bedrooms and 2 bathrooms. The size of the property is 846.0 square'), Document(page_content='Property is located in Goldcrest Highlife, DHA Defence Phase 2, Islamabad. The price of the property is 12300000. It has 2 bedrooms and 2 bathrooms. The size of the property is 1305.0 square')] \n",
      "\n",
      "        User: hi[/INST]  Hello! I'm PropertyPal, here to help you find the perfect property. Can you please provide me with more details about what you're looking for? For example, what location are you interested in, how many bedrooms and bathrooms do you want, and what is your budget? \n",
      "\n",
      "        Context: [Document(page_content='Property is located in FECHS, E-11/2, 2_FECHS. The price of the property is 60000000. It has 8 bedrooms and 9 bathrooms. The size of the property is 4500.0 square'), Document(page_content='Property is located in FECHS, E-11/2, 2_FECHS. The price of the property is 60000000. It has 8 bedrooms and 9 bathrooms. The size of the property is 4500.0 square'), Document(page_content='Property is located in FECHS, E-11/2, 2_FECHS. The price of the property is 60000000. It has 8 bedrooms and 9 bathrooms. The size of the property is 4500.0 square'), Document(page_content='Property is located in FECHS, E-11/2, 2_FECHS. The price of the property is 52000000. It has 7 bedrooms and 8 bathrooms. The size of the property is 4500.0 square')] \n",
      "\n",
      "        User: im looking for a property in FECHS E-11/2 with 8 bedrooms and size of 4500 square feet[/INST]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import anvil.server\n",
    "\n",
    "# Connect to the Anvil server\n",
    "anvil.server.connect(\"server_GHCXZYPN7FYGDDV2IRDBJFIG-5EMKN7KUZ3BZKLXO\")\n",
    "\n",
    "# Define your function to handle bot response\n",
    "@anvil.server.callable\n",
    "def get_bot_response(prompt):\n",
    "    # Use the getAnswer function to get the response from the model\n",
    "    response_text = getAnswer(chain, prompt)\n",
    "    return response_text\n",
    "\n",
    "# Keep the connection alive\n",
    "# Uncomment if needed\n",
    "# anvil.server.wait_forever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79edb6-615b-4c67-bef7-3ba71b195f18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
